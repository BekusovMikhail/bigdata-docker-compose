{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from nltk.corpus import stopwords # импорт проходит успешна, а загрузка стоп-слов что бы я не пробовал не проходит\n",
    "from nltk import word_tokenize # импорт проходит успешна, а загрузка стоп-слов что бы я не пробовал не проходит\n",
    "import re\n",
    "\n",
    "class Top_bigram(MRJob):\n",
    "    def mapper_1_init(self):\n",
    "        # stopwords = open(\"/data/stopwords/corpora/stopwords/english\").read() # не работает на хадупе ни в какую...\n",
    "        # self.stop_words = set(stopwords.words(\"english\")) # не работает на хадупе ни в какую...\n",
    "        self.stopwords = [\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"you're\",\"you've\",\"you'll\",\"you'd\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"she's\",\"her\",\"hers\",\"herself\",\"it\",\"it's\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"that'll\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"don't\",\"should\",\"should've\",\"now\",\"d\",\"ll\",\"m\",\"o\",\"re\",\"ve\",\"y\",\"ain\",\"aren\",\"aren't\",\"couldn\",\"couldn't\",\"didn\",\"didn't\",\"doesn\",\"doesn't\",\"hadn\",\"hadn't\",\"hasn\",\"hasn't\",\"haven\",\"haven't\",\"isn\",\"isn't\",\"ma\",\"mightn\",\"mightn't\",\"mustn\",\"mustn't\",\"needn\",\"needn't\",\"shan\",\"shan't\",\"shouldn\",\"shouldn't\",\"wasn\",\"wasn't\",\"weren\",\"weren't\",\"won\",\"won't\",\"wouldn\",\"wouldn't\",]\n",
    "        pass\n",
    "    def mapper_1(self, _, line):\n",
    "        icp = [x for x in line.split('\"') if x != \"\" and x != \" \"]\n",
    "        if len(icp) == 3:\n",
    "            try:\n",
    "                phrase = icp[2]\n",
    "                # stop_words = self.stop_words\n",
    "                cleaned_line = re.sub(r\"[^\\w\\s]\", \"\", phrase.lower())\n",
    "                words = [\n",
    "                    word\n",
    "                    for word in word_tokenize(cleaned_line)\n",
    "                #     if word not in stop_words\n",
    "                ]\n",
    "                # words = phrase.split(\" \")\n",
    "                # words = [x for x in words if x != \"\" and x != \" \"]\n",
    "                bigrams = [\n",
    "                    f\"{words[i]} {words[i+1]}\" for i in range(len(words) - 1)\n",
    "                ]\n",
    "                for bigram in bigrams:\n",
    "                    yield bigram, 1\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def reducer_1(self, bigram, counts):\n",
    "        yield None, (bigram, sum(counts))\n",
    "\n",
    "    def reducer_2(self, _, bigram_counts):\n",
    "        sorted_bigrams = sorted(\n",
    "            bigram_counts, key=lambda x: x[1], reverse=True\n",
    "        )[:20]\n",
    "        for bigram, count in sorted_bigrams:\n",
    "            yield bigram, count\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper_init=self.mapper_1_init, mapper=self.mapper_1, reducer=self.reducer_1),\n",
    "            MRStep(reducer=self.reducer_2),\n",
    "        ]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Top_bigram().run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
